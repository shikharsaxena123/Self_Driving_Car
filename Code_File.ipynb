{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shikh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From C:\\Users\\shikh\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from scipy import pi\n",
    "from itertools import islice\n",
    "import model\n",
    "import cv2\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis from steering angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing data.txt\n"
     ]
    }
   ],
   "source": [
    "# read images and steering angles from driving_dataset folder\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from scipy import pi\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "\n",
    "DATA_FOLDER = './driving_dataset' # change this to your folder\n",
    "TRAIN_FILE = os.path.join(DATA_FOLDER, 'data.txt')\n",
    "LIMIT = None\n",
    "\n",
    "split =0.7\n",
    "X = []\n",
    "y = []\n",
    "with open(TRAIN_FILE) as fp:\n",
    "    for line in islice(fp, LIMIT):\n",
    "        path, angle = line.strip().split()\n",
    "        full_path = os.path.join(DATA_FOLDER, path)\n",
    "        X.append(full_path)\n",
    "        \n",
    "        # converting angle from degrees to radians\n",
    "        y.append(float(angle) * pi / 180 )\n",
    "\n",
    "\n",
    "y = np.array(y)\n",
    "print(\"Completed processing data.txt\")\n",
    "\n",
    "split_index = int(len(y)*split)\n",
    "\n",
    "train_y = y[:split_index]\n",
    "test_y = y[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31784,)\n",
      "(13622,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_y))\n",
    "print(np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.hist(train_y, bins=50, density=1, color='blue', histtype ='step');\n",
    "plt.hist(test_y, bins=50, density=1, color='red', histtype ='step');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_MSE(MEAN):0.241561\n",
      "Test_MSE(ZERO):0.241107\n"
     ]
    }
   ],
   "source": [
    "#Model 0: Base line Model: y_test_pred = mean(y_train_i) \n",
    "train_mean_y = np.mean(train_y)\n",
    "\n",
    "print('Test_MSE(MEAN):%f' % np.mean(np.square(test_y-train_mean_y)) )\n",
    "\n",
    "print('Test_MSE(ZERO):%f' % np.mean(np.square(test_y-0.0)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driving_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import random\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "#points to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "with open(\"driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "split =0.7\n",
    "\n",
    "train_xs = xs[:int(len(xs) * split)]\n",
    "train_ys = ys[:int(len(xs) * split)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.3):]\n",
    "val_ys = ys[-int(len(xs) * 0.3):]\n",
    "\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images = len(val_xs)\n",
    "\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(train_xs[(train_batch_pointer + i) % num_train_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(val_xs[(val_batch_pointer + i) % num_val_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\shikh\\anaconda3\\lib\\site-packages (8.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45406,)\n",
      "(45406,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(ys))\n",
    "print(np.shape(xs))\n",
    "ys[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.misc' has no attribute 'imresize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-244f66b520fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_xs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m66\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.misc' has no attribute 'imresize'"
     ]
    }
   ],
   "source": [
    "scipy.misc.imresize(scipy.misc.imread(train_xs[0])[-150:], [66, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Linear Activation unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "rate = 0.5                                # dropout of 50%\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, rate)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, rate)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, rate)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, rate)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "# https://keras.io/activations/\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/activations/linear\n",
    "\n",
    "y = tf.multiply(tf.keras.activations.linear(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the data\n",
    "#### Linear activation unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "import driving_data\n",
    "import model\n",
    "\n",
    "startTime = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime)\n",
    "\n",
    "LOGDIR = './save_assignment'\n",
    "\n",
    "sess=tf.compat.v1.InteractiveSession()\n",
    "\n",
    "L2NormConst = 0.001\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(model.y_, model.y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "train_step = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# merge all summaries into a single op\n",
    "merged_summary_op =  tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "logs_path = './logs_assignment'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 7\n",
    "batch_size = 100\n",
    "\n",
    "# train over the dataset about 30 times\n",
    "for epoch in range(epochs):\n",
    "  for i in range(int(driving_data.num_images/batch_size)):\n",
    "    xs, ys = driving_data.LoadTrainBatch(batch_size)\n",
    "    train_step.run(feed_dict={model.x: xs, model.y_: ys, model.rate: 0.8})\n",
    "    if i % 10 == 0:\n",
    "      xs, ys = driving_data.LoadValBatch(batch_size)\n",
    "      loss_value = loss.eval(feed_dict={model.x:xs, model.y_: ys, model.rate: 1.0})\n",
    "      print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "    # write logs at every iteration\n",
    "    summary = merged_summary_op.eval(feed_dict={model.x:xs, model.y_: ys, model.rate: 1.0})\n",
    "    summary_writer.add_summary(summary, epoch * driving_data.num_images/batch_size + i)\n",
    "\n",
    "    if i % batch_size == 0:\n",
    "      if not os.path.exists(LOGDIR):\n",
    "        os.makedirs(LOGDIR)\n",
    "      checkpoint_path = os.path.join(LOGDIR, \"model.ckpt\")\n",
    "      filename = saver.save(sess, checkpoint_path)\n",
    "  print(\"Model saved in file: %s\" % filename)\n",
    "\n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=./logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n",
    "\n",
    "print(\"Time taken for creation of dataframe is {}\".format(datetime.datetime.now() - startTime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install opencv-python\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import model\n",
    "import cv2\n",
    "from subprocess import call\n",
    "import math\n",
    "\n",
    "sess=tf.compat.v1.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"save_assignment/model.ckpt\")\n",
    "\n",
    "img = cv2.imread('steering_wheel_image.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "\n",
    "#read data.txt\n",
    "xs = []\n",
    "ys = []\n",
    "with open(\"driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "\n",
    "i = math.ceil(num_images*0.7)\n",
    "print(\"Starting frameofvideo:\" +str(i))\n",
    "\n",
    "while(cv2.waitKey(10) != ord('q')):\n",
    "    full_image = scipy.misc.imread(\"driving_dataset/\" + str(i) + \".jpg\", mode=\"RGB\")\n",
    "    image = scipy.misc.imresize(full_image[-150:], [66, 200]) / 255.0\n",
    "    degrees = model.y.eval(feed_dict={model.x: [image], model.rate: 1.0})[0][0] * 180.0 / scipy.pi\n",
    "    #call(\"clear\")\n",
    "    #print(\"Predicted Steering angle: \" + str(degrees))\n",
    "    print(\"Steering angle: \" + str(degrees) + \" (pred)\\t\" + str(ys[i]*180/scipy.pi) + \" (actual)\")\n",
    "    cv2.imshow(\"frame\", cv2.cvtColor(full_image, cv2.COLOR_RGB2BGR))\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    smoothed_angle += 0.3 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"steering wheel\", dst)\n",
    "    i += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Softmax Activation unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "rate = 0.5                                # dropout of 50%\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, rate)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, rate)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, rate)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, rate)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "# https://keras.io/activations/\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/activations/linear\n",
    "\n",
    "y = tf.multiply(tf.keras.activations.softmax(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the data\n",
    "#### Linear activation unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "import driving_data\n",
    "import model\n",
    "\n",
    "startTime = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime)\n",
    "\n",
    "LOGDIR = './save_assignment'\n",
    "\n",
    "sess=tf.compat.v1.InteractiveSession()\n",
    "\n",
    "L2NormConst = 0.01\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(model.y_, model.y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# merge all summaries into a single op\n",
    "merged_summary_op =  tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "logs_path = './logs_assignment'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "# train over the dataset about 30 times\n",
    "for epoch in range(epochs):\n",
    "  for i in range(int(driving_data.num_images/batch_size)):\n",
    "    xs, ys = driving_data.LoadTrainBatch(batch_size)\n",
    "    train_step.run(feed_dict={model.x: xs, model.y_: ys, model.rate: 0.8})\n",
    "    if i % 10 == 0:\n",
    "      xs, ys = driving_data.LoadValBatch(batch_size)\n",
    "      loss_value = loss.eval(feed_dict={model.x:xs, model.y_: ys, model.rate: 1.0})\n",
    "      print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "    # write logs at every iteration\n",
    "    summary = merged_summary_op.eval(feed_dict={model.x:xs, model.y_: ys, model.rate: 1.0})\n",
    "    summary_writer.add_summary(summary, epoch * driving_data.num_images/batch_size + i)\n",
    "\n",
    "    if i % batch_size == 0:\n",
    "      if not os.path.exists(LOGDIR):\n",
    "        os.makedirs(LOGDIR)\n",
    "      checkpoint_path = os.path.join(LOGDIR, \"model_softmax.ckpt\")\n",
    "      filename = saver.save(sess, checkpoint_path)\n",
    "  print(\"Model saved in file: %s\" % filename)\n",
    "\n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=./logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n",
    "\n",
    "print(\"Time taken for creation of dataframe is {}\".format(datetime.datetime.now() - startTime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install opencv-python\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import model\n",
    "import cv2\n",
    "from subprocess import call\n",
    "import math\n",
    "\n",
    "sess=tf.compat.v1.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"save_assignment/model_softmax.ckpt\")\n",
    "\n",
    "img = cv2.imread('steering_wheel_image.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "\n",
    "#read data.txt\n",
    "xs = []\n",
    "ys = []\n",
    "with open(\"driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "\n",
    "i = math.ceil(num_images*0.7)\n",
    "print(\"Starting frameofvideo:\" +str(i))\n",
    "\n",
    "while(cv2.waitKey(10) != ord('q')):\n",
    "    full_image = scipy.misc.imread(\"driving_dataset/\" + str(i) + \".jpg\", mode=\"RGB\")\n",
    "    image = scipy.misc.imresize(full_image[-150:], [66, 200]) / 255.0\n",
    "    degrees = model.y.eval(feed_dict={model.x: [image], model.rate: 1.0})[0][0] * 180.0 / scipy.pi\n",
    "    #call(\"clear\")\n",
    "    #print(\"Predicted Steering angle: \" + str(degrees))\n",
    "    print(\"Steering angle: \" + str(degrees) + \" (pred)\\t\" + str(ys[i]*180/scipy.pi) + \" (actual)\")\n",
    "    cv2.imshow(\"frame\", cv2.cvtColor(full_image, cv2.COLOR_RGB2BGR))\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    smoothed_angle += 0.3 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"steering wheel\", dst)\n",
    "    i += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with tanh Activation unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "rate = 0.5                                # dropout of 50%\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, rate)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, rate)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, rate)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, rate)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "# https://keras.io/activations/\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/activations/linear\n",
    "\n",
    "y = tf.multiply(tf.keras.activations.tanh(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the data\n",
    "#### tanh activation unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "import driving_data\n",
    "import model\n",
    "\n",
    "startTime = datetime.datetime.now()\n",
    "print(\"Current Time = \",startTime)\n",
    "\n",
    "LOGDIR = './save_assignment'\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "L2NormConst = 0.001\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(model.y_, model.y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "train_step = tf.train.AdamOptimizer(0.0001).minimize(loss)\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# merge all summaries into a single op\n",
    "merged_summary_op =  tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "logs_path = './logs_assignment'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 7\n",
    "batch_size = 100\n",
    "\n",
    "# train over the dataset about 30 times\n",
    "for epoch in range(epochs):\n",
    "  for i in range(int(driving_data.num_images/batch_size)):\n",
    "    xs, ys = driving_data.LoadTrainBatch(batch_size)\n",
    "    train_step.run(feed_dict={model.x: xs, model.y_: ys, model.rate: 0.8})\n",
    "    if i % 10 == 0:\n",
    "      xs, ys = driving_data.LoadValBatch(batch_size)\n",
    "      loss_value = loss.eval(feed_dict={model.x:xs, model.y_: ys, model.rate: 1.0})\n",
    "      print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "    # write logs at every iteration\n",
    "    summary = merged_summary_op.eval(feed_dict={model.x:xs, model.y_: ys, model.rate: 1.0})\n",
    "    summary_writer.add_summary(summary, epoch * driving_data.num_images/batch_size + i)\n",
    "\n",
    "    if i % batch_size == 0:\n",
    "      if not os.path.exists(LOGDIR):\n",
    "        os.makedirs(LOGDIR)\n",
    "      checkpoint_path = os.path.join(LOGDIR, \"model_tanh.ckpt\")\n",
    "      filename = saver.save(sess, checkpoint_path)\n",
    "  print(\"Model saved in file: %s\" % filename)\n",
    "\n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=./logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n",
    "\n",
    "print(\"Time taken for creation of dataframe is {}\".format(datetime.datetime.now() - startTime))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install opencv-python\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import model\n",
    "import cv2\n",
    "from subprocess import call\n",
    "import math\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"save_assignment/model_tanh.ckpt\")\n",
    "\n",
    "img = cv2.imread('steering_wheel_image.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "\n",
    "#read data.txt\n",
    "xs = []\n",
    "ys = []\n",
    "with open(\"driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "\n",
    "i = math.ceil(num_images*0.7)\n",
    "print(\"Starting frameofvideo:\" +str(i))\n",
    "\n",
    "while(cv2.waitKey(10) != ord('q')):\n",
    "    full_image = scipy.misc.imread(\"driving_dataset/\" + str(i) + \".jpg\", mode=\"RGB\")\n",
    "    image = scipy.misc.imresize(full_image[-150:], [66, 200]) / 255.0\n",
    "    degrees = model.y.eval(feed_dict={model.x: [image], model.rate: 1.0})[0][0] * 180.0 / scipy.pi\n",
    "    #call(\"clear\")\n",
    "    #print(\"Predicted Steering angle: \" + str(degrees))\n",
    "    print(\"Steering angle: \" + str(degrees) + \" (pred)\\t\" + str(ys[i]*180/scipy.pi) + \" (actual)\")\n",
    "    cv2.imshow(\"frame\", cv2.cvtColor(full_image, cv2.COLOR_RGB2BGR))\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    smoothed_angle += 0.3 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"steering wheel\", dst)\n",
    "    i += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
